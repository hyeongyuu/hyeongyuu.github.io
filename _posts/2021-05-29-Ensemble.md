---
layout: single
title: "Ensemble"
excerpt: ""

date: 2023-02-04

categories:
    - Machine learning
tags:
    - Machine learning

# toc: true
# toc_label: "content"
# toc_icon: "bars"
# toc_sticky: true
---
<br>

앙상블(Ensemble)은 프랑스어로 단어 자체의 의미가 조화, 통일을 뜻한다. 머신러닝에서 앙상블은
여러 모델을 조화시켜 하나의 새로운 모델을 만드는 것을 의미하며, 여러 모델의 조합으로 만들어졌기 때문에 일반적으로 더욱 좋은 성능을 보여준다. 앙상블의 기본 원리를 알면 앙상블을 왜 사용하는지 이해가능하다. 데이터의 크기가 작다면, 한가지 기법만 사용해 하나의 모델만 생성하여 적용해도 모델이 좋은 성능을 보여줄것이다. 그러나 현재 대부분의 데이터는 크기가 크고 다양해서 하나의 모델만만으로 데이터를 충분히 설명하기 어렵다. 이러한 문제점을 해결하기 위해 모델 각각의 특징을 결합한 새로운 모델을 생성하는 앙상블 기법을 사용하는 것이다.


![KakaoTalk_Photo_2021-05-29-18-32-54](https://user-images.githubusercontent.com/82218035/120065878-93b6b800-c0ae-11eb-8ee7-9df1c9f8b80d.png)


실생활을 예로 축구팀에 빗대어보자. 팀에 공격수만 있다면, 공격은 잘되지만 수비수가 없어 골을 잘 먹혀 대회에서 좋은 성적을 거두지 못할것이다. 공격수와 수비수가 둘다 있는 공격과 수비에 밸런스를 맞춘 조화로운 팀을 만든다면 한가지에 특출난 팀보다 우수한 성적을 거둘것이다. 축구선수 한명을 모델로 보고 팀의 성적을 모델의 성능이라 가정해보면, 축구는 혼자 팀을 하는 것보다 선수가 많을수록, 공격수만 있는팀 보다 다양한 포지션의 선수가 있는 팀일수록 좋은 성적을 거둘것이다. 앙상블도 마찬가지로 모델은 많을수록, 다양한 모델이 있을수록 좋은 성능을 보여주는 것이다.

<br>
앙상블에는 보팅(Voting), 배깅(Bagging), 부스팅(Boosting) 방식이 있다. 보팅과 배깅은 완성된 모델을 결합하는 방식이라면, 부스팅은 모델을 수정해가면서 계속해서 새로운 모델을 만드는 방식이다. 보팅부터 살펴보면, 보팅은 크게 하드 보팅(Hard Voting)과 소프트 보팅(Soft Voting)으로 나뉜다. 두 방법 모두 모델마다 투표권을 갖고 결과에 대한 투표권을 행사하여 많은 득표를 받은 값을 최종 값으로 선정하는 투표 방식의 앙상블 기법으로 하드 보팅은 각 모델의 결과값을 종합하여 많이 나온 값을 최종 값으로 정하는 방식이고 소프트 보팅은 모델의 결과값이 나올 각 확률을 결합하여 최종 값을 정하는 방식이다.

<br>
<img width="648" alt="스크린샷 2021-05-29 오후 6 36 59" src="https://user-images.githubusercontent.com/82218035/120065891-a9c47880-c0ae-11eb-9041-dc9c8fa8f61d.png">

하드 보팅은 말그대로 투표권을 분산 없이 하나의 값에 부여하여 비슷한 확률 값을 갖는 결과는 무시해버리는 경우가 생겨 소프트 보팅보다 유연성 측면에서 떨어진다. 앙상블 원리 자체가 여러 모델을 결합하고자 하는 것인데, 하드 보팅은 모델을 결합한다기보다 결과값을 취합하는 방식같다는 개인적인 느낌이 들어 앙상블의 취지에 부합하지 않다는 생각이 든다. 그래서 일반적으로 하드 보팅보다는 소프트 보팅을 선호하는 경향이 있고 성능적인 측면에서도 소프트 보팅이 더 좋은 성능을 보여주기도 한다.

<br>
![KakaoTalk_Photo_2021-05-29-18-32-49](https://user-images.githubusercontent.com/82218035/120065883-97e2d580-c0ae-11eb-887a-7b20bb4503d9.png)

배깅은 보팅과 비슷한 방식으로 둘은 자주 비교된다. 보팅은 서로 다른 알고리즘을 활용한 모델을 결합하는 것이고, 배깅은 같은 알고리즘을 활용한 모델에 데이터를 다르게 적용하여 생성된 모델을 결합하는 방식이다. 배깅과 보팅은 같은 알고리즘을 활용하느냐, 다른 데이터를 활용하느냐가 두 방식의 차이점이라 생각한다.  
마지막으로 부스팅은 앞의 보팅, 배깅과 다르게 모델을 결합한다기보다 계속적으로 모델을 업데이트하는 방식이다. 생성한 모델을 검증 데이터에 적용해 오분류 데이터를 찾고 오분류 데이터에 가중치를 부여해 오분류 데이터를 잘 분류하도록 다음 모델을 업데이트 한다. 이런 과정을 여러번 반복하다보면 최종적으로 생성한 모델은 에러와 오차가 줄어드는 것이다.

앙상블은 현재시점에서 정형데이터에 좋은 성능을 보여주고있다. 데이터가 이미지나, 텍스트 등의 복잡한 데이터가 아니라면 머신러닝의 단순한 알고리즘을 앙상블시키면 충분한 성능을 보여준다는 것이다. 아직까지 관계형데이터베이스(RDB)의 정형데이터를 자주 접하고 있기 때문에 앙상블을 잘 활용한다면 좋은 모델을 만들 수 있다.
>딥러닝 모델도 앙상블을 통해 성능을 높이는 방식도 가능하다.

<br>

###### 결론
- 앙상블은 여러 모델을 조화시켜 하나의 새로운 모델을 만드는 것을 의미한다.
- 모델은 많을수록, 다양한 모델이 있을수록 좋은 성능을 보여준다.
- 앙상블 기법은 모델 각각의 특징을 결합한 새로운 모델을 생성한다.
